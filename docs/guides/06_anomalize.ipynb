{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Anomaly Detection\n",
        "toc: true\n",
        "toc-depth: 3\n",
        "number-sections: true\n",
        "number-depth: 2\n",
        "---"
      ],
      "id": "4b92d273"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anomaly detection in time series analysis is a crucial process for identifying unusual patterns that deviate from expected behavior. These anomalies can signify critical, often unforeseen events in time series data. Effective anomaly detection helps in maintaining the quality and reliability of data, ensuring accurate forecasting and decision-making. The challenge lies in distinguishing between true anomalies and natural fluctuations, which demands sophisticated analytical techniques and a deep understanding of the underlying time series patterns. As a result, anomaly detection is an essential component of time series analysis, driving the proactive management of risks and opportunities in dynamic environments.\n",
        "\n",
        "Pytimetk uses the following methods to determine anomalies in time series data;\n",
        "\n",
        "1. **Decomposition of Time Series:**\n",
        "\n",
        "   * The first step is to decompose the time series into several components. Commonly, this includes **trend**, **seasonality**, and **remainder** (or residual) components.\n",
        "\n",
        "   * Trend represents the underlying pattern or direction in the data over time.\n",
        "\tSeasonality captures recurring patterns or cycles over a specific period, such as daily, weekly, monthly, etc.\n",
        "\n",
        "   * The remainder (or residual) is what's left after the trend and seasonal components have been removed from the original time series.\n",
        "\n",
        "\n",
        "2. **Generating Remainders:**\n",
        "\n",
        "   * After decomposition, the remainder component is extracted. This component reflects the part of the time series that cannot be explained by the trend and seasonal components.\n",
        "\n",
        "   * The idea is that while trend and seasonality represent predictable and thus \"normal\" patterns, the remainder is where anomalies are most likely to manifest.\n",
        "\n",
        "\n",
        "There are 2 common techniques for seasonal decomposition; STL and Twitter;\n",
        "\n",
        "* **STL** (Seasonal and Trend Decomposition) is a versatile and robust method for decomposing time series. STL works very well in circumstances where a long term trend is present. The Loess algorithm typically does a very good job at detecting the trend. However, it circumstances when the seasonal component is more dominant than the trend, Twitter tends to perform better.\n",
        "\n",
        "* **Twitter** method is a similar decomposition method to that used in Twitter‚Äôs AnomalyDetection package. The Twitter method works identically to STL for removing the seasonal component. The main difference is in removing the trend, which is performed by removing the median of the data rather than fitting a smoother. The median works well when a long-term trend is less dominant that the short-term seasonal component. This is because the smoother tends to overfit the anomalies.\n",
        "\n",
        "# Anomaly Detection in Pytimetk\n",
        "This section will demonstrate how to use the set of `anomalize` functions for in pytimetk;\n",
        "\n",
        "* `anomalize()`\n",
        "* `plot_anomalies()`\n",
        "* `plot_anomalies_decomp()`\n",
        "* `plot_anomalies_cleaned()`\n",
        "\n",
        "## Setup\n",
        "To setup, import the necessary packages and the `m4_daily_df` dataset;\n"
      ],
      "id": "eec9b8f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# libraries\n",
        "import pytimetk as tk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import Data\n",
        "m4_daily_df = tk.load_dataset('m4_daily', parse_dates = ['date'])"
      ],
      "id": "bebc314c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Let's first demonstrate with a single time series. We'll filter `m4_daily_df`\n",
        " for `id` = `D10` and `date` within the year 2015.\n"
      ],
      "id": "d2595507"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data filtering\n",
        "df = (\n",
        "\tm4_daily_df\n",
        "\t\t.query(\"id == 'D10'\")\n",
        "\t\t.query(\"date.dt.year == 2015\")\n",
        ")"
      ],
      "id": "579608a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " We can plot this data to see the trend\n"
      ],
      "id": "7feaf171"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot data\n",
        "tk.plot_timeseries(\n",
        "\tdata \t\t = df,\n",
        " \tdate_column  = 'date',\n",
        " \tvalue_column = 'value'\n",
        ")"
      ],
      "id": "ddb88247",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seasonal Decomposition & Remainder\n",
        "First we perform seasonal decomposition and on the data and generate remainders using `anomalize()`.\n",
        "\n",
        "::: {.callout-tip collapse=\"false\"}\n",
        "## Help Doc Info: `anomalize()`\n",
        "Use `help(tk.anomalize)` to review additional helpful documentation.\n",
        ":::\n"
      ],
      "id": "9248b68d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Anomalize\n",
        "anomalize_df = tk.anomalize(\n",
        "\tdata          = df,\n",
        "\tdate_column   = 'date',\n",
        "\tvalue_column  = 'value',\n",
        "\tperiod        = 7,\n",
        "    iqr_alpha     = 0.05, # using the default\n",
        "    clean_alpha   = 0.75, # using the default\n",
        "    clean         = \"min_max\"\n",
        ")\n",
        "\n",
        "anomalize_df.glimpse()"
      ],
      "id": "d9cd40c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Seasonal Decomposition\n",
        "We plot the seaonal decomposition to get a visual representation;\n",
        "\n",
        "::: {.callout-tip collapse=\"false\"}\n",
        "## Help Doc Info: `plot_anomalies_decomp()`\n",
        "Use `help(tk.plot_anomalies_decomp)` to review additional helpful documentation.\n",
        ":::\n"
      ],
      "id": "3d84f9cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot seasonal decomposition\n",
        "tk.plot_anomalies_decomp(\n",
        "\tdata        = anomalize_df,\n",
        "\tdate_column = 'date',\n",
        "\tengine      = 'plotly',\n",
        "\ttitle       = 'Seasonal Decomposition'\n",
        ")"
      ],
      "id": "5f0295bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Anomalies\n",
        "Next we can plot the anomalies using `tk.plot_anomalies()`;\n",
        "\n",
        "::: {.callout-tip collapse=\"false\"}\n",
        "## Help Doc Info: `plot_anomalies()`\n",
        "Use `help(tk.plot_anomalies)` to review additional helpful documentation.\n",
        ":::\n"
      ],
      "id": "db051bdf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot anomalies\n",
        "tk.plot_anomalies(\n",
        "\tdata        = anomalize_df,\n",
        "\tdate_column = 'date',\n",
        "\tengine      = 'plotly',\n",
        "\ttitle       = 'Plot Anomaly Bands'\n",
        ")"
      ],
      "id": "6e2ff815",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Cleaned Anomalies\n",
        "Finally we can also see a plot of the data with cleaned anomalies using `plot_anomalies_cleaned()`;\n",
        "\n",
        "::: {.callout-tip collapse=\"false\"}\n",
        "## Help Doc Info: `plot_anomalies_cleaned()`\n",
        "Use `help(tk.plot_anomalies_cleaned)` to review additional helpful documentation.\n",
        ":::\n"
      ],
      "id": "f3d6d5a1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot cleaned anomalies\n",
        "tk.plot_anomalies_cleaned(\n",
        "\tdata        = anomalize_df,\n",
        "\tdate_column = 'date'\n",
        ")"
      ],
      "id": "202ea7da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changing Parameters\n",
        "Some important parameters to hightlight in the `anomalize()` function include `iqr_alpha`.\n",
        "\n",
        "::: {.callout-important collapse=\"false\"}\n",
        "`iqr_alpha` controls the threshold for detecting outliers. It is the significance level used in the interquartile range (IQR) method for outlier detection. The default value is 0.05, which corresponds to a 5% significance level. A lower significance level will result in a higher threshold, which means fewer outliers will be detected. A higher significance level will result in a lower threshold, which means more outliers will be detected.\n",
        ":::\n",
        "\n",
        "Lets visualize the effect of changing the `iqr_alpha` parameter;\n",
        "\n",
        "### Changing `iqr_alpha`\n",
        "First, lets get a dataframe with multiple values for `iqr_alpha`;\n"
      ],
      "id": "71dafd47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Anomalized data with multiple iqr_alpha values\n",
        "\n",
        "# - Alpha values\n",
        "iqr_alpha_values = [0.05, 0.10, 0.15, 0.20]\n",
        "\n",
        "# - Empty dataframes list\n",
        "dfs = []\n",
        "\n",
        "for alpha in iqr_alpha_values:\n",
        "\n",
        "\t# - Run anomalize function\n",
        "    anomalize_df = tk.anomalize(\n",
        "        data         = df,\n",
        "        date_column  = 'date',\n",
        "        value_column = 'value',\n",
        "        period       = 7,\n",
        "        iqr_alpha    = alpha\n",
        "    )\n",
        "\n",
        "    # - Add the iqr_alpha column\n",
        "    anomalize_df['iqr_alpha'] = f'iqr_alpha value of {alpha}'\n",
        "\n",
        "    # - Append to the list\n",
        "    dfs.append(anomalize_df)\n",
        "\n",
        "# - Concatenate all dataframes\n",
        "final_df = pd.concat(dfs)"
      ],
      "id": "48c7726b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can visualize the anomalies:\n",
        "\n",
        "### Visualizing Grouped Anomalies (Facets)\n"
      ],
      "id": "03f59867"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize\n",
        "(\n",
        "\tfinal_df\n",
        "\t\t.groupby('iqr_alpha')\n",
        "\t\t.plot_anomalies(\n",
        "\t\t\tdate_column = 'date',\n",
        "\t\t\tengine      = 'plotly',\n",
        "\t\t\tfacet_ncol  = 2\n",
        "\t\t)\n",
        ")"
      ],
      "id": "ee071f93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Grouped Anomalies (Plotly Dropdown)\n"
      ],
      "id": "1a3886b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize\n",
        "(\n",
        "\tfinal_df\n",
        "\t\t.groupby('iqr_alpha')\n",
        "\t\t.plot_anomalies(\n",
        "\t\t\tdate_column     = 'date',\n",
        "\t\t\tengine          = 'plotly',\n",
        "\t\t\tplotly_dropdown = True,\n",
        "\t\t\tplotly_dropdown_x = 1,\n",
        "\t\t\tplotly_dropdown_y = 0.60\n",
        "\t\t)\n",
        ")"
      ],
      "id": "defee720",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More Coming Soon...\n",
        "\n",
        "We are in the early stages of development. But it's obvious the potential for `pytimetk` now in Python. üêç\n",
        "\n",
        "- Please [‚≠ê us on GitHub](https://github.com/business-science/pytimetk) (it takes 2-seconds and means a lot). \n",
        "- To make requests, please see our [Project Roadmap GH Issue #2](https://github.com/business-science/pytimetk/issues/2). You can make requests there. \n",
        "- Want to contribute? [See our contributing guide here.](/contributing.html) \n"
      ],
      "id": "8d0d0b39"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}